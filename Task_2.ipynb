{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f672d8e",
   "metadata": {},
   "source": [
    "## Task 2 - Retail Strategy and Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ea20a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "D:\\ANACONDA\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n",
      "D:\\ANACONDA\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# importing all required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bce86b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LYLTY_CARD_NBR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>STORE_NBR</th>\n",
       "      <th>TXN_ID</th>\n",
       "      <th>PROD_NBR</th>\n",
       "      <th>PROD_NAME</th>\n",
       "      <th>PROD_QTY</th>\n",
       "      <th>TOT_SALES</th>\n",
       "      <th>PACK_SIZE</th>\n",
       "      <th>BRAND</th>\n",
       "      <th>LIFESTAGE</th>\n",
       "      <th>PREMIUM_CUSTOMER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>2018-10-17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Natural Chip        Compny SeaSalt175g</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>175</td>\n",
       "      <td>NATURAL</td>\n",
       "      <td>YOUNG SINGLES/COUPLES</td>\n",
       "      <td>Premium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>2018-09-16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>Red Rock Deli Chikn&amp;Garlic Aioli 150g</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>150</td>\n",
       "      <td>RRD</td>\n",
       "      <td>YOUNG SINGLES/COUPLES</td>\n",
       "      <td>Mainstream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>2019-03-07</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>Grain Waves Sour    Cream&amp;Chives 210G</td>\n",
       "      <td>1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>210</td>\n",
       "      <td>GRNWVES</td>\n",
       "      <td>YOUNG FAMILIES</td>\n",
       "      <td>Budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>2019-03-08</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>106</td>\n",
       "      <td>Natural ChipCo      Hony Soy Chckn175g</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>175</td>\n",
       "      <td>NATURAL</td>\n",
       "      <td>YOUNG FAMILIES</td>\n",
       "      <td>Budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>2018-11-02</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "      <td>WW Original Stacked Chips 160g</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>160</td>\n",
       "      <td>WOOLWORTHS</td>\n",
       "      <td>OLDER SINGLES/COUPLES</td>\n",
       "      <td>Mainstream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264829</th>\n",
       "      <td>2370701</td>\n",
       "      <td>2018-12-08</td>\n",
       "      <td>88</td>\n",
       "      <td>240378</td>\n",
       "      <td>24</td>\n",
       "      <td>Grain Waves         Sweet Chilli 210g</td>\n",
       "      <td>2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>210</td>\n",
       "      <td>GRNWVES</td>\n",
       "      <td>YOUNG FAMILIES</td>\n",
       "      <td>Mainstream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264830</th>\n",
       "      <td>2370751</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>88</td>\n",
       "      <td>240394</td>\n",
       "      <td>60</td>\n",
       "      <td>Kettle Tortilla ChpsFeta&amp;Garlic 150g</td>\n",
       "      <td>2</td>\n",
       "      <td>9.2</td>\n",
       "      <td>150</td>\n",
       "      <td>KETTLE</td>\n",
       "      <td>YOUNG FAMILIES</td>\n",
       "      <td>Premium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264831</th>\n",
       "      <td>2370961</td>\n",
       "      <td>2018-10-24</td>\n",
       "      <td>88</td>\n",
       "      <td>240480</td>\n",
       "      <td>70</td>\n",
       "      <td>Tyrrells Crisps     Lightly Salted 165g</td>\n",
       "      <td>2</td>\n",
       "      <td>8.4</td>\n",
       "      <td>165</td>\n",
       "      <td>TYRRELLS</td>\n",
       "      <td>OLDER FAMILIES</td>\n",
       "      <td>Budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264832</th>\n",
       "      <td>2370961</td>\n",
       "      <td>2018-10-27</td>\n",
       "      <td>88</td>\n",
       "      <td>240481</td>\n",
       "      <td>65</td>\n",
       "      <td>Old El Paso Salsa   Dip Chnky Tom Ht300g</td>\n",
       "      <td>2</td>\n",
       "      <td>10.2</td>\n",
       "      <td>300</td>\n",
       "      <td>OLD</td>\n",
       "      <td>OLDER FAMILIES</td>\n",
       "      <td>Budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264833</th>\n",
       "      <td>2373711</td>\n",
       "      <td>2018-12-14</td>\n",
       "      <td>88</td>\n",
       "      <td>241815</td>\n",
       "      <td>16</td>\n",
       "      <td>Smiths Crinkle Chips Salt &amp; Vinegar 330g</td>\n",
       "      <td>2</td>\n",
       "      <td>11.4</td>\n",
       "      <td>330</td>\n",
       "      <td>SMITHS</td>\n",
       "      <td>YOUNG SINGLES/COUPLES</td>\n",
       "      <td>Mainstream</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264834 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        LYLTY_CARD_NBR        DATE  STORE_NBR  TXN_ID  PROD_NBR  \\\n",
       "0                 1000  2018-10-17          1       1         5   \n",
       "1                 1002  2018-09-16          1       2        58   \n",
       "2                 1003  2019-03-07          1       3        52   \n",
       "3                 1003  2019-03-08          1       4       106   \n",
       "4                 1004  2018-11-02          1       5        96   \n",
       "...                ...         ...        ...     ...       ...   \n",
       "264829         2370701  2018-12-08         88  240378        24   \n",
       "264830         2370751  2018-10-01         88  240394        60   \n",
       "264831         2370961  2018-10-24         88  240480        70   \n",
       "264832         2370961  2018-10-27         88  240481        65   \n",
       "264833         2373711  2018-12-14         88  241815        16   \n",
       "\n",
       "                                       PROD_NAME  PROD_QTY  TOT_SALES  \\\n",
       "0         Natural Chip        Compny SeaSalt175g         2        6.0   \n",
       "1          Red Rock Deli Chikn&Garlic Aioli 150g         1        2.7   \n",
       "2          Grain Waves Sour    Cream&Chives 210G         1        3.6   \n",
       "3         Natural ChipCo      Hony Soy Chckn175g         1        3.0   \n",
       "4                 WW Original Stacked Chips 160g         1        1.9   \n",
       "...                                          ...       ...        ...   \n",
       "264829     Grain Waves         Sweet Chilli 210g         2        7.2   \n",
       "264830      Kettle Tortilla ChpsFeta&Garlic 150g         2        9.2   \n",
       "264831   Tyrrells Crisps     Lightly Salted 165g         2        8.4   \n",
       "264832  Old El Paso Salsa   Dip Chnky Tom Ht300g         2       10.2   \n",
       "264833  Smiths Crinkle Chips Salt & Vinegar 330g         2       11.4   \n",
       "\n",
       "        PACK_SIZE       BRAND              LIFESTAGE PREMIUM_CUSTOMER  \n",
       "0             175     NATURAL  YOUNG SINGLES/COUPLES          Premium  \n",
       "1             150         RRD  YOUNG SINGLES/COUPLES       Mainstream  \n",
       "2             210     GRNWVES         YOUNG FAMILIES           Budget  \n",
       "3             175     NATURAL         YOUNG FAMILIES           Budget  \n",
       "4             160  WOOLWORTHS  OLDER SINGLES/COUPLES       Mainstream  \n",
       "...           ...         ...                    ...              ...  \n",
       "264829        210     GRNWVES         YOUNG FAMILIES       Mainstream  \n",
       "264830        150      KETTLE         YOUNG FAMILIES          Premium  \n",
       "264831        165    TYRRELLS         OLDER FAMILIES           Budget  \n",
       "264832        300         OLD         OLDER FAMILIES           Budget  \n",
       "264833        330      SMITHS  YOUNG SINGLES/COUPLES       Mainstream  \n",
       "\n",
       "[264834 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the Dataset\n",
    "df = pd.read_csv('QVI_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a79f26",
   "metadata": {},
   "source": [
    "The client has selected store numbers 77, 86 and 88 as trial stores with a trial period of Feb 2019 to April 2019. The client also wants control stores to be established stores that are operational for the entire observation period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac76dec",
   "metadata": {},
   "source": [
    "We would want to match trial stores to control stores that are similar to the trial store prior to the trial period of Feb 2019 in terms of:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32161624",
   "metadata": {},
   "source": [
    "- Monthly overall sales revenue\n",
    "- Monthly number of customers\n",
    "- Monthly number of transactions per customer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a571622",
   "metadata": {},
   "source": [
    "To choose the control stores, we will create the metrics of interest and filter to stores that are present throughout the pre-trial period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7c45eb",
   "metadata": {},
   "source": [
    "First, we want to add a column with the year/month of the transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f7ffcd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LYLTY_CARD_NBR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>STORE_NBR</th>\n",
       "      <th>TXN_ID</th>\n",
       "      <th>PROD_NBR</th>\n",
       "      <th>PROD_NAME</th>\n",
       "      <th>PROD_QTY</th>\n",
       "      <th>TOT_SALES</th>\n",
       "      <th>PACK_SIZE</th>\n",
       "      <th>BRAND</th>\n",
       "      <th>LIFESTAGE</th>\n",
       "      <th>PREMIUM_CUSTOMER</th>\n",
       "      <th>YEARMONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>2018-10-17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Natural Chip        Compny SeaSalt175g</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>175</td>\n",
       "      <td>NATURAL</td>\n",
       "      <td>YOUNG SINGLES/COUPLES</td>\n",
       "      <td>Premium</td>\n",
       "      <td>201810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>2018-09-16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>Red Rock Deli Chikn&amp;Garlic Aioli 150g</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>150</td>\n",
       "      <td>RRD</td>\n",
       "      <td>YOUNG SINGLES/COUPLES</td>\n",
       "      <td>Mainstream</td>\n",
       "      <td>201809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>2019-03-07</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>Grain Waves Sour    Cream&amp;Chives 210G</td>\n",
       "      <td>1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>210</td>\n",
       "      <td>GRNWVES</td>\n",
       "      <td>YOUNG FAMILIES</td>\n",
       "      <td>Budget</td>\n",
       "      <td>201903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>2019-03-08</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>106</td>\n",
       "      <td>Natural ChipCo      Hony Soy Chckn175g</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>175</td>\n",
       "      <td>NATURAL</td>\n",
       "      <td>YOUNG FAMILIES</td>\n",
       "      <td>Budget</td>\n",
       "      <td>201903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>2018-11-02</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "      <td>WW Original Stacked Chips 160g</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>160</td>\n",
       "      <td>WOOLWORTHS</td>\n",
       "      <td>OLDER SINGLES/COUPLES</td>\n",
       "      <td>Mainstream</td>\n",
       "      <td>201811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LYLTY_CARD_NBR       DATE  STORE_NBR  TXN_ID  PROD_NBR  \\\n",
       "0            1000 2018-10-17          1       1         5   \n",
       "1            1002 2018-09-16          1       2        58   \n",
       "2            1003 2019-03-07          1       3        52   \n",
       "3            1003 2019-03-08          1       4       106   \n",
       "4            1004 2018-11-02          1       5        96   \n",
       "\n",
       "                                PROD_NAME  PROD_QTY  TOT_SALES  PACK_SIZE  \\\n",
       "0  Natural Chip        Compny SeaSalt175g         2        6.0        175   \n",
       "1   Red Rock Deli Chikn&Garlic Aioli 150g         1        2.7        150   \n",
       "2   Grain Waves Sour    Cream&Chives 210G         1        3.6        210   \n",
       "3  Natural ChipCo      Hony Soy Chckn175g         1        3.0        175   \n",
       "4          WW Original Stacked Chips 160g         1        1.9        160   \n",
       "\n",
       "        BRAND              LIFESTAGE PREMIUM_CUSTOMER  YEARMONTH  \n",
       "0     NATURAL  YOUNG SINGLES/COUPLES          Premium     201810  \n",
       "1         RRD  YOUNG SINGLES/COUPLES       Mainstream     201809  \n",
       "2     GRNWVES         YOUNG FAMILIES           Budget     201903  \n",
       "3     NATURAL         YOUNG FAMILIES           Budget     201903  \n",
       "4  WOOLWORTHS  OLDER SINGLES/COUPLES       Mainstream     201811  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the DATE column to store dates as datetime\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "\n",
    "# Adding a YEARMONTH column\n",
    "df['YEARMONTH'] = df['DATE'].dt.strftime('%Y%m').astype('int64')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0cfdab",
   "metadata": {},
   "source": [
    "Next, we want to create a function that will be able to calculate the total sales, number of customers, transactions per cutomer, chips per customer and the average price per unit for each store and month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a8e6780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the metrics and calculate them\n",
    "grouped_df = df.groupby([\"STORE_NBR\",\"YEARMONTH\"])\n",
    "tot_sales = grouped_df.TOT_SALES.sum()\n",
    "n_cust = grouped_df.LYLTY_CARD_NBR.nunique()\n",
    "ntrans_percust = grouped_df.TXN_ID.size()/n_cust\n",
    "nchips_pertrans = grouped_df.PROD_QTY.sum()/grouped_df.TXN_ID.size()\n",
    "avg_priceperunit = tot_sales/grouped_df.PROD_QTY.sum()\n",
    "# Put the metrics together in an array\n",
    "metric_arrays =  [tot_sales, n_cust, ntrans_percust, nchips_pertrans, avg_priceperunit]\n",
    "\n",
    "# Create the metrics table fro mthe array \n",
    "metrics_df = pd.concat(metric_arrays, axis=1)\n",
    "# Give the columns labels \n",
    "metrics_df.columns = ['tot_sales', 'n_cust', 'ntrans_percust', 'nchips_pertrans', 'avg_priceperunit']\n",
    "metrics_df = metrics_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "978b9cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORE_NBR</th>\n",
       "      <th>YEARMONTH</th>\n",
       "      <th>tot_sales</th>\n",
       "      <th>n_cust</th>\n",
       "      <th>ntrans_percust</th>\n",
       "      <th>nchips_pertrans</th>\n",
       "      <th>avg_priceperunit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>201807</td>\n",
       "      <td>206.9</td>\n",
       "      <td>49</td>\n",
       "      <td>1.061224</td>\n",
       "      <td>1.192308</td>\n",
       "      <td>3.337097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>201808</td>\n",
       "      <td>176.1</td>\n",
       "      <td>42</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>1.255814</td>\n",
       "      <td>3.261111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>201809</td>\n",
       "      <td>278.8</td>\n",
       "      <td>59</td>\n",
       "      <td>1.050847</td>\n",
       "      <td>1.209677</td>\n",
       "      <td>3.717333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>201810</td>\n",
       "      <td>188.1</td>\n",
       "      <td>44</td>\n",
       "      <td>1.022727</td>\n",
       "      <td>1.288889</td>\n",
       "      <td>3.243103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>201811</td>\n",
       "      <td>192.6</td>\n",
       "      <td>46</td>\n",
       "      <td>1.021739</td>\n",
       "      <td>1.212766</td>\n",
       "      <td>3.378947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159</th>\n",
       "      <td>272</td>\n",
       "      <td>201809</td>\n",
       "      <td>304.7</td>\n",
       "      <td>32</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.972222</td>\n",
       "      <td>4.291549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3160</th>\n",
       "      <td>272</td>\n",
       "      <td>201810</td>\n",
       "      <td>430.6</td>\n",
       "      <td>44</td>\n",
       "      <td>1.159091</td>\n",
       "      <td>1.941176</td>\n",
       "      <td>4.349495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3161</th>\n",
       "      <td>272</td>\n",
       "      <td>201811</td>\n",
       "      <td>376.2</td>\n",
       "      <td>41</td>\n",
       "      <td>1.097561</td>\n",
       "      <td>1.933333</td>\n",
       "      <td>4.324138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3162</th>\n",
       "      <td>272</td>\n",
       "      <td>201812</td>\n",
       "      <td>403.9</td>\n",
       "      <td>47</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.893617</td>\n",
       "      <td>4.538202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>272</td>\n",
       "      <td>201901</td>\n",
       "      <td>423.0</td>\n",
       "      <td>46</td>\n",
       "      <td>1.086957</td>\n",
       "      <td>1.920000</td>\n",
       "      <td>4.406250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1820 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      STORE_NBR  YEARMONTH  tot_sales  n_cust  ntrans_percust  \\\n",
       "0             1     201807      206.9      49        1.061224   \n",
       "1             1     201808      176.1      42        1.023810   \n",
       "2             1     201809      278.8      59        1.050847   \n",
       "3             1     201810      188.1      44        1.022727   \n",
       "4             1     201811      192.6      46        1.021739   \n",
       "...         ...        ...        ...     ...             ...   \n",
       "3159        272     201809      304.7      32        1.125000   \n",
       "3160        272     201810      430.6      44        1.159091   \n",
       "3161        272     201811      376.2      41        1.097561   \n",
       "3162        272     201812      403.9      47        1.000000   \n",
       "3163        272     201901      423.0      46        1.086957   \n",
       "\n",
       "      nchips_pertrans  avg_priceperunit  \n",
       "0            1.192308          3.337097  \n",
       "1            1.255814          3.261111  \n",
       "2            1.209677          3.717333  \n",
       "3            1.288889          3.243103  \n",
       "4            1.212766          3.378947  \n",
       "...               ...               ...  \n",
       "3159         1.972222          4.291549  \n",
       "3160         1.941176          4.349495  \n",
       "3161         1.933333          4.324138  \n",
       "3162         1.893617          4.538202  \n",
       "3163         1.920000          4.406250  \n",
       "\n",
       "[1820 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter to select the stores with full observation periods \n",
    "month_counts = metrics_df.groupby('STORE_NBR').YEARMONTH.nunique().reset_index()\n",
    "stores_fullobs = month_counts[month_counts.YEARMONTH ==12].STORE_NBR\n",
    "pretrial_metrics = metrics_df[metrics_df['STORE_NBR'].isin(stores_fullobs)]\n",
    "\n",
    "# Then filter to keep only the pre-trial period data\n",
    "pretrial_metrics = pretrial_metrics.loc[pretrial_metrics.YEARMONTH < 201902]\n",
    "pretrial_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737912a8",
   "metadata": {},
   "source": [
    "Now we need to work out a way of ranking how similar each potential control store is to the trial store. We can calculate how correlated the performance of each potential control store is to the trial store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f0d3e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to calculate the correlation between a trial store and all possible control stores \n",
    "# Inputs: \n",
    "    # trial (int) : the trial store to test \n",
    "    # metric_col (str) : the label of the metric column to correlate \n",
    "    # input_table (df) : the full data table of metrics to obtain the correlations with \n",
    "# Output:\n",
    "    # corr_table (df) : a data frame with the year-month, trial store, control store and their correlation \n",
    "    \n",
    "def calc_corr(trial, metric_col, input_table = pretrial_metrics):\n",
    "    trial_stores = [77, 86, 88]\n",
    "    control_stores = stores_fullobs[~stores_fullobs.isin(trial_stores)] # all stores but trial stores \n",
    "    # Keep the trial store values to perform correlation with \n",
    "    trial_vals = input_table[input_table[\"STORE_NBR\"] == trial][metric_col].reset_index()\n",
    "    corr_table = pd.DataFrame(columns = ['YEARMONTH', 'trial_store', 'control_store', 'correlation']) \n",
    "    # Find the correlation for each control store \n",
    "    for control in control_stores:\n",
    "        # Keep the control store values to perform correlation with \n",
    "        control_vals = input_table[input_table[\"STORE_NBR\"] == control][metric_col].reset_index()\n",
    "        corr_row = pd.DataFrame(columns = ['YEARMONTH', 'trial_store', 'control_store', 'correlation'])\n",
    "        corr_row.YEARMONTH = list(input_table.loc[input_table.STORE_NBR == control][\"YEARMONTH\"])\n",
    "        corr_row.trial_store = trial\n",
    "        corr_row.control_store = control\n",
    "        corr_row.correlation = control_vals.corrwith(trial_vals, axis=1)\n",
    "        corr_table = pd.concat([corr_table, corr_row]) # add each store's block to the dataframe \n",
    "    return (corr_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1586647a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp/ipykernel_13732/421928630.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  corr_table = pd.concat([corr_table, corr_row]) # add each store's block to the dataframe\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp/ipykernel_13732/1990712463.py:5: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  corr_table = pd.concat([corr_table, corr_section])\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp/ipykernel_13732/421928630.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  corr_table = pd.concat([corr_table, corr_row]) # add each store's block to the dataframe\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp/ipykernel_13732/421928630.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  corr_table = pd.concat([corr_table, corr_row]) # add each store's block to the dataframe\n"
     ]
    }
   ],
   "source": [
    "trial_stores = [77, 86, 88]\n",
    "corr_table = pd.DataFrame(columns = ['YEARMONTH', 'trial_store', 'control_store', 'correlation'])\n",
    "for store in trial_stores:\n",
    "    corr_section = calc_corr(store, ['tot_sales', 'n_cust', 'ntrans_percust', 'nchips_pertrans', 'avg_priceperunit'] )\n",
    "    corr_table = pd.concat([corr_table, corr_section])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6fe6bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEARMONTH</th>\n",
       "      <th>trial_store</th>\n",
       "      <th>control_store</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201807</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201808</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201809</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201810</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.019991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201811</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201809</td>\n",
       "      <td>88</td>\n",
       "      <td>272</td>\n",
       "      <td>0.533160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201810</td>\n",
       "      <td>88</td>\n",
       "      <td>272</td>\n",
       "      <td>0.591056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201811</td>\n",
       "      <td>88</td>\n",
       "      <td>272</td>\n",
       "      <td>0.566378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>201812</td>\n",
       "      <td>88</td>\n",
       "      <td>272</td>\n",
       "      <td>0.594442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>201901</td>\n",
       "      <td>88</td>\n",
       "      <td>272</td>\n",
       "      <td>0.621775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5397 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEARMONTH trial_store control_store  correlation\n",
       "0     201807          77             1     0.070544\n",
       "1     201808          77             1     0.027332\n",
       "2     201809          77             1     0.002472\n",
       "3     201810          77             1    -0.019991\n",
       "4     201811          77             1     0.030094\n",
       "..       ...         ...           ...          ...\n",
       "2     201809          88           272     0.533160\n",
       "3     201810          88           272     0.591056\n",
       "4     201811          88           272     0.566378\n",
       "5     201812          88           272     0.594442\n",
       "6     201901          88           272     0.621775\n",
       "\n",
       "[5397 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae786aa",
   "metadata": {},
   "source": [
    "Apart from the correlation, we can also calculate a standardised metric based on the absolute difference between the trial store's preformance and each control store's performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825ba2eb",
   "metadata": {},
   "source": [
    "Writing a function to calculate the magnitude distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c914dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to calculate the normalised distance magnitude between a trial store and all possible control stores \n",
    "# Inputs: \n",
    "    # trial (int) : the trial store to test \n",
    "    # metric_col (str) : the label of the metric column to correlate \n",
    "    # input_table (df) : the full data table of metrics to obtain the correlations with \n",
    "# Output:\n",
    "    # corr_table (df) : a data frame with the year-month, trial store, control store and their normalised distance  \n",
    "    \n",
    "def calc_magdist(trial, metric_col, input_table = pretrial_metrics):\n",
    "    trial_stores = [77, 86, 88]\n",
    "    control_stores = stores_fullobs[~stores_fullobs.isin(trial_stores)] # all stores but the trials \n",
    "    dist_table = pd.DataFrame() # to store the distances for each store and month \n",
    "    for control in control_stores: # calculate for each control store \n",
    "        dist_row = pd.DataFrame()\n",
    "        # Calculate the distance as an absolute value \n",
    "        dist_row = abs(input_table[input_table[\"STORE_NBR\"] == trial].reset_index()[metric_col]\\\n",
    "                        - input_table[input_table[\"STORE_NBR\"] == control].reset_index()[metric_col])\n",
    "        dist_row.insert(0,'YEARMONTH', list(input_table.loc[input_table.STORE_NBR == trial][\"YEARMONTH\"]))\n",
    "        dist_row.insert(1,'trial_store', trial)\n",
    "        dist_row.insert(2,'control_store', control)\n",
    "        dist_table = pd.concat([dist_table, dist_row])\n",
    "        \n",
    "    for col in metric_col: # then loop over each column to find the max and min distances to normalise \n",
    "        maxdist = dist_table[col].max()\n",
    "        mindist = dist_table[col].min()\n",
    "        dist_table[col] = 1-(dist_table[col] - mindist)/(maxdist-mindist) # normalised distance measure \n",
    "        # also give an average magnitude over all metrics per month and store pair \n",
    "    dist_table['mag_measure'] = dist_table[metric_col].mean(axis=1)  \n",
    "    return (dist_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394d1b97",
   "metadata": {},
   "source": [
    "Now we will use the functions to find the control stores! We'll select control stores based on how similar monthly total sales in dollar amounts and monthly number of customers are to the trial stores. So we will need to use our functions to get four scores, two for each of total sales and total customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8d0f2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to generate a table of averaged correlations, distance and scores over the pretrial months for each store\n",
    "# Inputs:\n",
    "    # trial (int) : the trial store to test \n",
    "    # metric_col (str) : the metric label to calculate the scores for \n",
    "    # input_table (df) : the data to calculate the scores with in the pre-trial period \n",
    "# Output:\n",
    "    # avg_corrmag (df) : a table with the correlations, distance and scores averaged over the pretrial months for each store\n",
    "def calc_corrdist_score (trial, metric_col, input_table=pretrial_metrics):\n",
    "    # Calculate the correlations and magnitudes for all months \n",
    "    corr_vals = calc_corr(trial, metric_col, input_table)\n",
    "    mag_vals = calc_magdist(trial, metric_col, input_table)\n",
    "    mag_vals = mag_vals.drop(metric_col, axis=1) # For one metric, the two columns will be duplicates so drop one \n",
    "    \n",
    "    # Combine correlations and magnitudes together to one df\n",
    "    combined_corr_dist = pd.merge(corr_vals, mag_vals, on=[\"YEARMONTH\", \"trial_store\", \"control_store\"])\n",
    "    \n",
    "    # Average correlations and distances over the pre-trial months \n",
    "    avg_corrmag = combined_corr_dist.groupby([\"trial_store\", \"control_store\"]).mean().reset_index()\n",
    "    \n",
    "    # Find a combined score by taking the weighted average of the correlations and magnitudes \n",
    "    corr_weight = 0.5\n",
    "    avg_corrmag['combined_score'] = corr_weight*avg_corrmag['correlation'] + (1-corr_weight)*avg_corrmag['mag_measure']\n",
    "    \n",
    "    return(avg_corrmag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d097a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to output the 5 stores with the highest averaged scores combining the tot_sales and n_cust metrics\n",
    "# for a given trial store over the pre-trial period \n",
    "# Inputs:\n",
    "    # trial (int) : the trial store to test \n",
    "# Output:\n",
    "    # scores (df) : a sorted table with the 5 highest composite scores of possible control stores \n",
    "    \n",
    "def find_highestscore(trial):\n",
    "    # Obtain the scores for the tot_sales and n_cust metrics separately \n",
    "    scores_tot_sales = calc_corrdist_score (trial, ['tot_sales'])\n",
    "    scores_n_cust = calc_corrdist_score (trial, ['n_cust'])\n",
    "    # Create a data table to store the composite results in - stores are also \n",
    "    scores_control = pd.DataFrame()\n",
    "    scores_control['control_store'] = scores_tot_sales.control_store\n",
    "    # Calculate the composite scores \n",
    "    scores_control['correlation'] = 0.5*scores_tot_sales.correlation + 0.5*scores_n_cust.correlation\n",
    "    scores_control['mag_measure'] = 0.5*scores_tot_sales.mag_measure + 0.5*scores_n_cust.mag_measure\n",
    "    scores_control['scores'] = 0.5*scores_tot_sales.combined_score + 0.5*scores_n_cust.combined_score\n",
    "    return(scores_control.sort_values(by = 'scores', ascending = False).reset_index(drop = True).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e70881d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial store:  77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp/ipykernel_13732/421928630.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  corr_table = pd.concat([corr_table, corr_row]) # add each store's block to the dataframe\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp/ipykernel_13732/421928630.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  corr_table = pd.concat([corr_table, corr_row]) # add each store's block to the dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   control_store  correlation  mag_measure    scores\n",
      "0            233          1.0     0.989804  0.994902\n",
      "1             41          1.0     0.972041  0.986020\n",
      "2             46          1.0     0.969523  0.984762\n",
      "3             53          1.0     0.968421  0.984211\n",
      "4            111          1.0     0.967981  0.983991\n",
      "\n",
      "Trial store:  86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp/ipykernel_13732/421928630.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  corr_table = pd.concat([corr_table, corr_row]) # add each store's block to the dataframe\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp/ipykernel_13732/421928630.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  corr_table = pd.concat([corr_table, corr_row]) # add each store's block to the dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   control_store  correlation  mag_measure    scores\n",
      "0            155          1.0     0.976324  0.988162\n",
      "1            109          1.0     0.968180  0.984090\n",
      "2            225          1.0     0.965044  0.982522\n",
      "3            229          1.0     0.957995  0.978997\n",
      "4            101          1.0     0.945394  0.972697\n",
      "\n",
      "Trial store:  88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp/ipykernel_13732/421928630.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  corr_table = pd.concat([corr_table, corr_row]) # add each store's block to the dataframe\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp/ipykernel_13732/421928630.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  corr_table = pd.concat([corr_table, corr_row]) # add each store's block to the dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   control_store  correlation  mag_measure    scores\n",
      "0             40          1.0     0.941789  0.970895\n",
      "1             26          1.0     0.917859  0.958929\n",
      "2             72          1.0     0.908157  0.954079\n",
      "3             58          1.0     0.900435  0.950217\n",
      "4             81          1.0     0.887572  0.943786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now find the control stores with the highest scores for each of the trial stores \n",
    "trial_stores = [77, 86, 88]\n",
    "for trial in trial_stores:\n",
    "    print('Trial store: ', trial)\n",
    "    print(find_highestscore(trial))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58699338",
   "metadata": {},
   "source": [
    "From the above output, the stores with the highest scores are:\n",
    "\n",
    "- Store 233 for trial store 77\n",
    "- Store 155 for trial store 86\n",
    "- Store 40 for trial stre 88\n",
    "    \n",
    "Note that the combined store for the control cases of trial store 88 are lower than those of stores 77 and 86. This may suggest that the control stores may not match store 88 as well as for the other trial stores.\n",
    "\n",
    "Now that we have found the control stores, we can visually check if the drivers are similar between these and the trial stores in the pre-trial period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5606be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(storepair, metric_col):\n",
    "    trial = storepair[0]\n",
    "    control = storepair[1]\n",
    "    trial_plot = pretrial_metrics[pretrial_metrics.STORE_NBR == trial][['YEARMONTH', 'STORE_NBR', metric_col]]\n",
    "    trial_plot = trial_plot.rename(columns = {metric_col: metric_col+'_trial'})\n",
    "    control_plot = pretrial_metrics[pretrial_metrics.STORE_NBR == control][['YEARMONTH', 'STORE_NBR', metric_col]]\n",
    "    control_plot = control_plot.rename(columns = {metric_col: metric_col+'_control'})\n",
    "    \n",
    "    other_stores = pretrial_metrics.loc[(pretrial+metrics.STORE_NBR != 77)][['YEARMONTH', 'STORE_NBR', metric_col]]\n",
    "    other_stores = other_stores.loc[(pretrial_metrics.STORE_NBR != 233)]\n",
    "    plot_other = other_stores.groupby('YEARMONTH')[metric_col].mean()\n",
    "    \n",
    "    ax = control_plot.plot.line(x = 'YEARMONTH', y = metric_col+'_control', use_index=False, label = 'Control '+metric_col)\n",
    "    ax_trial = trial_plot.plot.line(x = 'YEARMONTH', y = metirc_col+'_trial', use_index=False, ax=ax, label= 'Trial '+metric_col)\n",
    "    ax_other = plot_other.plot.line(use_index = False, ax=ax, label = 'Other '+ metric_col)\n",
    "    ax.set_ylabel(metric_col)\n",
    "    plt.legend(title = 'STORE_NBR', loc = \"upper left\", bbox_to_anchor=(1.0, 1.0))\n",
    "    positions = (0, 1, 2, 3, 4, 5, 6)\n",
    "    labels = ('201807', '201808', '201809', '201810', '201811', '201812', '201901')\n",
    "    plt.xticks (positions, labels)\n",
    "    titlestr = 'The Trial Store ' + str(storepair[0]) + ' and Control Store ' + str(storepair[1]) + ' in the Pre-Trial Period'\n",
    "    ax.set_title(titlestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e2d8195",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pretrial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13732/706236770.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstorepair\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmetric_col\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mmake_plots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13732/3336501780.py\u001b[0m in \u001b[0;36mmake_plots\u001b[1;34m(storepair, metric_col)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcontrol_plot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontrol_plot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mmetric_col\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmetric_col\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_control'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mother_stores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpretrial_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrial\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTORE_NBR\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m77\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'YEARMONTH'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'STORE_NBR'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mother_stores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mother_stores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrial_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTORE_NBR\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m233\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mplot_other\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mother_stores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'YEARMONTH'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmetric_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pretrial' is not defined"
     ]
    }
   ],
   "source": [
    "storepair = [[77, 233], [86, 155], [88, 40]]\n",
    "metric_col = ['tot_sales', 'n_cust']\n",
    "for pair in storepair:\n",
    "    for metric in metric_col:\n",
    "        make_plots(pair, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cee234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
